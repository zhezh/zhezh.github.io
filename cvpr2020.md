---
layout: post
title: "Fusing Wearable IMUs with Multi-View Images for Human Pose Estimation: A Geometric Approach"
data: 2020-03-15 08:00:00 +0800

author: Zhe
---


<center> <b>(CVPR 2020)</b> </center>

<center>Zhe Zhang<sup>1,2</sup>, Chunyu Wang<sup>2</sup>, Wenhu Qin<sup>1</sup>, Wenjun Zeng<sup>2</sup></center>
<center><sup>1</sup>Southeast University, <sup>2</sup>Microsoft Research Asia</center>




![ORN pipeline graph](https://cdn.jsdelivr.net/gh/zhezh/zhezh.github.io@master/src/orn_pipeline.png)
<center>Figure 1. Pipeline overview of Orientation Regularized Network (ORN)</center>
<br />

**Abstract**
&emsp; We propose to estimate 3D human pose from multi-view images and a few IMUs attached at person's limbs. It operates by firstly detecting 2D poses from the two signals, and then lifting them to the 3D space. We present a geometric approach to reinforce the visual features of each pair of joints based on the IMUs. This notably improves 2D pose estimation accuracy especially when one joint is occluded. We call this approach Orientation Regularized Network (**ORN**).  Then we lift the multi-view 2D poses to the 3D space by an Orientation Regularized Pictorial Structure Model (**ORPSM**) which jointly minimizes the projection error between the 3D and 2D poses, along with the discrepancy between the 3D pose and IMU orientations. The simple two-step approach reduces the error of the state-of-the-art by a large margin on a public dataset.


![3d_results](https://cdn.jsdelivr.net/gh/zhezh/zhezh.github.io@master/src/3d_results.png)
<center>Figure 2. Example 3D results of challenging poses with severe self-occlusion</center>
<br />


### Demo Video

<iframe width="600" height="480" src="https://www.youtube.com/embed/-OhMsfsuRYI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<br />


### Code
- Paper: [arXiv](https://arxiv.org/abs/2003.11163)
- Code:  [{aka.ms/imu-human-pose}](https://aka.ms/imu-human-pose) [{Microsoft Official Github (Not yet available)}](https://github.com/microsoft/imu-human-pose-pytorch)
- TotalCapture Dataset Toolbox: [zhezh/TotalCapture-Toolbox](https://github.com/zhezh/TotalCapture-Toolbox)
- Poster: [PDF](https://cdn.jsdelivr.net/gh/zhezh/zhezh.github.io@master/src/cvpr2020/05755-poster.pdf)
- CVPR Virtual Meeting Online Materials: 
	- [{Slides}](https://cdn.jsdelivr.net/gh/zhezh/zhezh.github.io@master/src/cvpr2020/5755-slides.pdf) 
	- [{1Min Video on YouTube}](https://www.youtube.com/watch?v=KgtOUNGJxAM)
	- [{Teaser Image}](https://cdn.jsdelivr.net/gh/zhezh/zhezh.github.io@master/src/cvpr2020/05755-teaser.png) 
	- [{Teaser Text}](https://cdn.jsdelivr.net/gh/zhezh/zhezh.github.io@master/src/cvpr2020/5755-teaser.txt) 
	- [{KeyWords}](https://cdn.jsdelivr.net/gh/zhezh/zhezh.github.io@master/src/cvpr2020/5755-keywords.txt)


### BibTeX

```
@inproceedings{zhe2020fusingimu,
  title={Fusing Wearable IMUs with Multi-View Images for Human Pose Estimation: A Geometric Approach},
  author={Zhang, Zhe and Wang, Chunyu and Qin, Wenhu and Zeng, Wenjun},
  booktitle = {CVPR},
  year={2020}
}
```


